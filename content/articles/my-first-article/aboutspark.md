---
title: " 🌟 [Spark] About Spark "
description: "Spark 간단한 소개글입니다."
date: "2024-08-22"
banner:
  src: "../../images/spark-cover.png"
  alt: "Spark"
  caption: 'Photo by <u><a href="https://spark.apache.org">Spark</a></u>'
categories:
  - "Spark"
  - "ALL"
keywords:
  - "Pipeline"
  - "Big-Data"
  - "Blog"
  - "Spark"
---
# 💬 Apache Spark 소개

![Spark](https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-cover.png)

## ✅ 개요

**Apache Spark**는 대규모 데이터 처리에 최적화된 오픈 소스 분산 처리 시스템입니다. 

주로 빅데이터 분석에 사용되며, 빠른 속도와 유연성을 제공합니다. 

Spark는 메모리 내에서 데이터를 처리하기 때문에, 기존의 하둡(MapReduce)보다 훨씬 빠르게 데이터 분석 작업을 수행할 수 있습니다.

## ⚙️ 주요 특징

- **속도**: 메모리 내에서 연산을 수행하여 디스크 기반의 처리보다 최대 100배 빠른 성능을 자랑합니다.
- **사용 편의성**: 다양한 프로그래밍 언어(Scala, Python, Java, R)를 지원하며, 간단한 API로 복잡한 작업을 쉽게 구현할 수 있습니다.
- **유연성**: 배치 처리, 스트리밍 처리, SQL, 머신 러닝, 그래프 처리 등 다양한 데이터 처리 작업을 하나의 통합된 프레임워크에서 수행할 수 있습니다.
- **확장성**: 수천 대의 노드를 사용하는 클러스터에서 실행할 수 있어, 페타바이트 규모의 데이터도 효율적으로 처리할 수 있습니다.

## ⚒️ Spark의 주요 구성 요소

- **Spark Core**: Spark의 기본 엔진으로, 작업 스케줄링, 메모리 관리, 장애 복구 등의 기능을 제공합니다.
- **Spark SQL**: SQL과 비슷한 방식으로 구조화된 데이터를 처리할 수 있는 모듈입니다. 데이터 프레임(DataFrame)과 데이터셋(Dataset) API를 지원합니다.
- **Spark Streaming**: 실시간 스트리밍 데이터를 처리할 수 있는 모듈로, 배치 작업을 마이크로 배치로 전환하여 스트리밍 데이터를 처리합니다.
- **MLlib**: 머신 러닝 라이브러리로, 다양한 알고리즘과 도구들을 제공하여 빅데이터에 대한 머신 러닝 작업을 지원합니다.
- **GraphX**: 그래프와 병렬 연산을 위한 라이브러리로, 그래프 데이터에 대한 분석 작업을 수행할 수 있습니다.

## 📊 Spark의 활용 사례

- **데이터 분석**: 대규모 로그 데이터 분석, 추천 시스템 구현, 사용자 행동 분석 등 다양한 빅데이터 분석 작업에 활용됩니다.
- **실시간 처리**: 실시간 트랜잭션 분석, 실시간 데이터 스트리밍 처리, 실시간 데이터 시각화 등에 사용됩니다.
- **머신 러닝**: 대규모 데이터셋에 대한 머신 러닝 모델 학습, 데이터 전처리 및 피처 엔지니어링, 예측 모델링 등에 활용됩니다.

## 🧑🏻‍💻 결론

Apache Spark는 빠르고 유연하며 확장 가능한 데이터 처리 시스템으로, 빅데이터 시대의 필수 도구로 자리잡고 있습니다. 

데이터를 처리하고 분석하는 도구로 많이 사용하기 때문에 많은 실습과 공부를 해야겠다는 생각이 듭니다.

Spark-Streaming을 적용해서 프로젝트를 한 번 진행해야겠습니다. 😊

감사합니다.


