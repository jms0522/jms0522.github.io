{"componentChunkName":"component---node-modules-gatsby-theme-portfolio-minimal-src-templates-article-index-tsx","path":"/my-first-article/About-Kafka-Record/","result":{"pageContext":{"article":{"banner":{"alt":"Kafka","caption":null,"src":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB1klEQVR42pWS20vCYBTA/asC6UIEQVFa/QNdnFozTUjsQummZdZLSI9dtLQsNnvpRpFlD2l/wCJXUbTtqYTc5iaImp2pmGAPdeD7OJxzft93bqpSqSTLcvz2VhRF0AuFQrFYLP1NVHCWl7wGHeJyYhXTV1kqSiNQ81bhUb1hJ7CtH9HJknQVjdLJZI38apD6VxSYeXvr7OhgGTZCkmbUZBod41gW7DzPQwn1DCgf7+/pdDqfz1d/PiTJVnXzbjCkGxrGHE5I4fnpCYqfnZ4ReF6S5Iwovr68QOTVZdRus3ncC49JOpvNqu4pStvTyzLMgEa77Q8cHx0l4nGIy2QypjHU6/GcnZxO2+0TZjNqNGIOh33StrS46JybjxCEAvf1ajiO69dodwIKfJdIAAyJtbe2WS2Wm1gMALBAU/2bW3uh0ALualGrKYpS0o4QpLqpKRQMjgwOuTAcgiBtgN047ltdPQiHZ6amJq1WI6InCeIgvL+5vrHm88FdbhjD9HR1cywHPqvZMo6ilYbB5KGw9OcndIimaUEQsmWRJCmXy6VSKQU2IEhgy4/AqGT54vw8+fBQG1K12w1rU/Eq8IrXC6N2Y/ivS1L/Si3gZ87wYew6Jgr/Xs9vFqVLFScdcPIAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/63fdbbcf1c93c7c30e2a1c96954db211/be504/kafka.png","srcSet":"/static/63fdbbcf1c93c7c30e2a1c96954db211/966b5/kafka.png 80w,\n/static/63fdbbcf1c93c7c30e2a1c96954db211/37b8e/kafka.png 159w,\n/static/63fdbbcf1c93c7c30e2a1c96954db211/be504/kafka.png 318w","sizes":"(min-width: 318px) 318px, 100vw"},"sources":[{"srcSet":"/static/63fdbbcf1c93c7c30e2a1c96954db211/41d58/kafka.webp 80w,\n/static/63fdbbcf1c93c7c30e2a1c96954db211/d2420/kafka.webp 159w,\n/static/63fdbbcf1c93c7c30e2a1c96954db211/7b932/kafka.webp 318w","type":"image/webp","sizes":"(min-width: 318px) 318px, 100vw"}]},"width":660,"height":400.566037735849}}}},"body":"<h1>🚀 Apache Kafka Record</h1>\n<h2>🔎 Overview</h2>\n<p>카프카의 데이터를 부르는 명칭인 Record에 대하여.</p>\n<h2>Record</h2>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/kafka/record.png\" alt=\"Record\" width=\"600\">\n<h2>구조</h2>\n<p>레코드는 타임스탬프, 헤더 , 메시지 키, 오프셋으로 구성되어 있습니다.</p>\n<p>프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장이 됩니다.</p>\n<p>한 번 저장된 레코드는 임의로 삭제 할 수 없고 오직 로그의 리텐션 기간 및 용량을 설정해 놓은 값에 따라서 삭제 됩니다.</p>\n<h3>timestamp</h3>\n<p>시간을 저장하는 용도로 사용합니다.</p>\n<p>따로 설정을 하지 않으면 기본 값인 프로듀서의 생성 시간(CreateTime)이 들어가게 됩니다.</p>\n<p>혹은 브로커에 적재된 시간(LogAppendTime)으로 설정이 가능합니다.</p>\n<p>해당 옵션은 토픽 단위로 설정이 가능하며 log.message.timestamp.type 의 설정을 통해 가능합니다.</p>\n<p>이러한 옵션을 통해 메시지의 생성 시간과 적재 시간의 차이를 계산하여 네트워크 전송 지연 시간을 체크할 수 있을 것 같습니다.</p>\n<h3>offset</h3>\n<p>프로듀서가 전송한 레코드가 브로커에 적재 될 시점에 오프셋이 지정됩니다.</p>\n<p>0부터 시작하여 1씩 증가하게 되고 컨슈머는 오프셋을 기준으로 읽은 데이터와 처리해야 할 데이터를 구분합니다. (Commit)</p>\n<p>각 메시지는 파티션 별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리를 방지하기 위한 목적으로도 사용합니다.</p>\n<h3>Header</h3>\n<p>key/value 데이터를 추가할 수 있습니다.</p>\n<h3>Message key</h3>\n<p>메시지 값의 분류하기 위한 용도로 사용되며 이를 파티셔닝이라고 부릅니다.</p>\n<p>간단한 설명으로 메시지 키를 통해 어떤 파티션에 들어갈건지 지정할 수 있다고 생각하시면 됩니다.</p>\n<p>메시지 키를 지정하지 않으면 (null) RR 방식으로 파티션에 분배해 저장합니다.</p>\n<p>null이 아닌 메시지 키는 특정 파티션에 맵핑되어 전달됩니다.</p>\n<h3>Value</h3>\n<p>메시지 값은 실질적으로 처리 할 데이터가 담기는 공간입니다.</p>\n<p>메시지의 포맷 값은 사용자애 의해 지정이 되는데, 다양한 형태가 가능합니다.</p>\n<p>필요에 따라 사용자 지정 포맷으로 직렬화/역직렬화 클래스를 만들어 사용도 가능합니다.</p>\n<p>브로커에 저장된 레코드의 메시지 값은 어떤 포맷으로 직렬화 되어 저장되는지 알 수 없기에 컨슈머는 역직렬화 포맷을 알아야 합니다.</p>\n<p>여기서 잠깐 ☝️</p>\n<p>직렬화와 역직렬화는 데이터 무결성을 유지하고 전송 효율을 높여줍니다.</p>\n<p>정확히 무엇인지 한 번 봐보죠!</p>\n<h4>직렬화 Serialization ?</h4>\n<p>프로듀서와 컨슈머가 전송을 하고 수신을 할 때 데이터를 각각 직렬화 하고 역직렬화 하는데 이것은 kafka가 메시지를 바이트 배열 형식으로 처리하기 때문입니다.</p>\n<p>직렬화는 객체를 바이트 배열로 바꾸는거라 생각하면 될 것 같습니다.</p>\n<h4>역직렬화 Deserialization ?</h4>\n<p>바이트 배열을 원래 형식으로 복원하는 과정입니다.</p>\n<p>바이트 배열을 객체로 복원한다고 생각하시면 됩니다.</p>\n<h2>마무리</h2>\n<p>오늘은 record에 대해서 알아보았는데요.</p>\n<p>뭐든 하나하나 쉽게 가는 게 없는 거 같네요 😅</p>","categories":["Kafka","ALL"],"date":"October 28, 2024","description":"Kafka KRaft 소개글입니다.","id":"82e420b7-b6a7-5104-a377-f0e3b383e1f4","keywords":["Pipeline","Kafka"],"slug":"/my-first-article/About-Kafka-Record/","title":" 🚀 [Kafka] About Kafka Record","readingTime":{"text":"5 min read"}},"listingPagePath":"/blog"}},"staticQueryHashes":["3262260831","948380417"],"slicesMap":{}}