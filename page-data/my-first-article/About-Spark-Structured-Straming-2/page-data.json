{"componentChunkName":"component---node-modules-gatsby-theme-portfolio-minimal-src-templates-article-index-tsx","path":"/my-first-article/About-Spark-Structured-Straming-2/","result":{"pageContext":{"article":{"banner":{"alt":"Spark","caption":"Photo by <u><a href=\"https://spark.apache.org/streaming/\">Spark Streaming</a></u>","src":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAABKklEQVR42o2S3UvDMBTF94crDp+UOR8m6iaCU5ko3Z6GdtBG6frdPYgvE6Z0XSuKlcZ+0I1ikxrtEMfasvNwSeD+cpKTW0pWEcYJRj91UaWszgURDKN4mcyA58C/LalB72x6f/flvM1vUeDseV4YhtCBvu8H09mMOY802r3aiZ4ffmGUAacm9rvdPDlVFRWAW4EXJEnhLo4vW62Absa2leucwpb1Ut7Y3N6q1A8be7X9amW3WjtYWy9/vFoJinHem1MYQkgMGYZ1HMcYG6PR08SYmKb56bq5gaWkruttqjMcPvJ9XlU1WVYUWQEsEAVpoA3IQX+dmfCYojqiKNM3PZYB3e41x/XJQhLlRv2IBEF6EEJFaWeK5B9FUdE/E3+UI7zKkOQPKF7mvwHvMaPrfenbCQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/6334b12b709ea25b787ddf070a70ab16/bc51f/spark-st-cover.png","srcSet":"/static/6334b12b709ea25b787ddf070a70ab16/41200/spark-st-cover.png 165w,\n/static/6334b12b709ea25b787ddf070a70ab16/f979a/spark-st-cover.png 330w,\n/static/6334b12b709ea25b787ddf070a70ab16/bc51f/spark-st-cover.png 660w","sizes":"(min-width: 660px) 660px, 100vw"},"sources":[{"srcSet":"/static/6334b12b709ea25b787ddf070a70ab16/322ad/spark-st-cover.webp 165w,\n/static/6334b12b709ea25b787ddf070a70ab16/de3b3/spark-st-cover.webp 330w,\n/static/6334b12b709ea25b787ddf070a70ab16/2b2b5/spark-st-cover.webp 660w","type":"image/webp","sizes":"(min-width: 660px) 660px, 100vw"}]},"width":660,"height":400}}}},"body":"<h1>💬 Apache Spark Streaming -2</h1>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-practice/spark-work.png\" alt=\"work\" width=\"600\">\n<h1>🌟 Apache Spark 구조적 스트리밍(Structured Streaming)</h1>\n<p>오늘은 <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\">Apache Spark docs</a>를 읽고 그에 대한 내용을 정리하겠습니다.</p>\n<p>지금 Kafka와 Spark를 이용해 실시간 데이터 처리를 하고 있는데 docs를 읽어보면 훨씬 도움이 될 거 같습니다.</p>\n<h2>✅ 핵심 아이디어</h2>\n<p>구조적 스트리밍에 대한 핵심 아이디어는 <strong>스트림 데이터를 지속적으로 추가되는 테이블로 처리</strong>하는 것입니다.</p>\n<p>스트리밍 데이터를 정적 테이블과 같이 표현하고 이를 무제한 입력 테이블에서 <strong>증분 쿼리</strong>로 실행하는 것, 이것이 핵심인 거 같습니다.</p>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-practice/idea.png\" alt=\"work\" width=\"600\">\n<p>밑에 사진을 보시면 **'입력되는 데이터 스트림'**을 **'입력테이블'**로 간주하여 도착하는 모든 데이터는 입력 테이블에 추가되는 Row와 같다는 것!</p>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-practice/basicidea.png\" alt=\"work\" width=\"600\">\n<p>또한 입력에 대한 결과는 <strong>결과 테이블</strong>을 생성하여 입력 테이블에 추가되는 데이터를 결과 테이블에 업데이트 합니다.</p>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-practice/answertable.png\" alt=\"work\" width=\"600\">\n<p>여기서의 Output은 외부 저장소에 쓰여지는 걸 의미합니다.</p>\n<p>출력은 3가지 모드로 정의할 수 있고, 상황에 맞춰 사용하면 됩니다. (설명 생략) 🙏🏻</p>\n<ul>\n<li>전체 모드</li>\n<li>추가 모드</li>\n<li>업데이트 모드 (2.11 부터 사용 가능)</li>\n</ul>\n<p>이 예시를 보면 정확히 이해할 수 있습니다.</p>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-practice/ex.png\" alt=\"work\" width=\"600\">\n<p>왼쪽에서 오른쪽으로 데이터가 들어오고 wordcount를 query를 통해 결과 테이블로 업데이트된 카운트를 계산하는 <strong>증분</strong> 쿼리를 진행하고 있습니다.</p>\n<p>❗️<strong>Structured Streaming</strong>에서 중요한 점은 <strong>전체 테이블을 구체화 하지 않는다</strong>는 점입니다.</p>\n<p>여기서 최신 데이터를 읽고 결과를 업데이트한 뒤 <strong>소스 데이터는 버린다</strong>는 점입니다.</p>\n<h2>✅ 결함 허용</h2>\n<p>내결함성을 1회 보장 (정확한 한 번)</p>\n<p>스파크 스트리밍은 진행상황 등을 안정적으로 추적하여 재시작 또는 재처리를 통해 오류상황을 처리하여 내결함성을 1회 보장한다.</p>\n<h2>📊 주요 측면</h2>\n<img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/spark-practice/4side.png\" alt=\"work\" width=\"600\">\n<ul>\n<li>\n<p>오류, 지연 작업 발생 시 신속한 복구가 가능</p>\n<ul>\n<li>\n<p>장애 발생 시 체크포인트를 활용하여 복구</p>\n</li>\n<li>\n<p>자동으로 작업을 다른 노드로 재비치 가능 (유연한 실패 복구)</p>\n</li>\n</ul>\n</li>\n<li>\n<p>로드 밸런싱과 리소스 사용률 개선</p>\n<ul>\n<li>\n<p>자동 스케일링 : 처리량 증가시 클러스터 크기 확장 및 축소 가능</p>\n</li>\n<li>\n<p>동적 리소스 할당 : 동적으로 자원 할당 (CPU, 메모리 등)</p>\n</li>\n</ul>\n</li>\n<li>\n<p>정적 Dataset와 인터랙티브 쿼리를 사용해 스트리밍 데이터 결합</p>\n<ul>\n<li>\n<p>스트리밍 데이터와 정적 데이터 결합이 가능 -> 복합적인 분석이 가능</p>\n</li>\n<li>\n<p>실시간 처리 동시에 쿼리를 통해 실시간 분석이 가능 -> 풍부한 인사이트 제공</p>\n</li>\n</ul>\n</li>\n<li>\n<p>고급 처리 라이브러리(SQL, 머신 러닝, 그래프 처리)와 네이티브 방식으로 통합</p>\n<ul>\n<li>머신 러닝, 그래프 관계 분석 등 다양한 라이브러리로 효율적인 분석 기능 사용 가능</li>\n</ul>\n</li>\n</ul>","categories":["Spark","Streaming","ALL"],"date":"September 05, 2024","description":"Spark의 구조적 스트리밍에 대해.","id":"d934fb55-a218-576a-ba19-c2159757596a","keywords":["Pipeline","Streaming","Blog","Spark"],"slug":"/my-first-article/About-Spark-Structured-Straming-2/","title":" 🌟 [Spark] Structured Streaming -2 ","readingTime":{"text":"5 min read"}},"listingPagePath":"/blog"}},"staticQueryHashes":["3262260831","948380417"],"slicesMap":{}}