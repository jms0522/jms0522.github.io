{"componentChunkName":"component---node-modules-gatsby-theme-portfolio-minimal-src-templates-article-index-tsx","path":"/my-first-article/About-Airflow-Practice/","result":{"pageContext":{"article":{"banner":{"alt":"Airflow","caption":"Photo by <u><a href=\"https://airflow.apache.org\">Airflow</a></u>","src":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAACO0lEQVR42oWS3WvTUBTAb+dk4qNPIvgB/gH1A31xyEAnExR88GH4MJ8EBYdPIoh78MUnBd2LWVs2sV1bV9subl0qQjs6ZpdEU21T027DNV0b1vXbmJI1TeNJU3Gg4IHce88593dzvpBaLGggqqrqm1ZTWk9zRVltw7n9l/y+1RUkXDLLVMTgwX2Vy5z9utYltf8Iypw6tD1k1jhG0bSRNI8WmespHhybuVwyyRa2trLZrCAIqRS3mk7zPN9oNIyndbh0+uDm5ZPag+GxcBiRKbT05d73PDhI+pPf5/XD99aDz86Gw6GlSMTpnC6Xy39gZvCMds2ceXz7WDCM6DTAju0qOHYURZblSqUCqyj+aDabakfAUq/X1U6OaPihEx+7c3SRRJROHqa5UlPR4aYy/uJ5uVyq1WpsImEkub6+Zre/9vm8Ql6PDvXho3tj0T3fiiYysf/z6vuaaNxLJpNWi+Xj8jLESdNUIDBPEMTU5CSGvbRMYBzHgQX1fDjfR4weyFaOCDsLkgyY0umHzWYNBgmb1cqy7Nzcu2mHQ5KkGMOsrEQpinK5nHBAJv+V3pkBFLh1M7WgR6u2YC0UChMYFo/H3W4X1CwUCnk8HkiSYRggo9EoWHAcR8g/YPIM9novojfnHrGvjJgl6We1qpcNGgMPiaIIKsCgwv9BVRQly/MI25jf5xtC7v4edz+yn7gbGzd4tW1UV/3neHRbpddQzD9Lz9wgn1yI3D9OjExtBMHY6sS/ezZ3q8ZA/wIAVki+U9pyEAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/de7402d2a87d0256451392f6590d157b/b7b7c/airflow-profile.png","srcSet":"/static/de7402d2a87d0256451392f6590d157b/182cc/airflow-profile.png 91w,\n/static/de7402d2a87d0256451392f6590d157b/2c6ad/airflow-profile.png 181w,\n/static/de7402d2a87d0256451392f6590d157b/b7b7c/airflow-profile.png 362w","sizes":"(min-width: 362px) 362px, 100vw"},"sources":[{"srcSet":"/static/de7402d2a87d0256451392f6590d157b/98c2e/airflow-profile.webp 91w,\n/static/de7402d2a87d0256451392f6590d157b/483ec/airflow-profile.webp 181w,\n/static/de7402d2a87d0256451392f6590d157b/def5b/airflow-profile.webp 362w","type":"image/webp","sizes":"(min-width: 362px) 362px, 100vw"}]},"width":660,"height":399.2817679558011}}}},"body":"<h1>🌬️ Apache Airflow: 공부하기</h1>\n<p><img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/airflow-profile.png\" alt=\"Airflow\"></p>\n<h1>🔫 Airflow를 활용한 Faker 데이터 생성 * 활용하기</h1>\n<h2>🌟 프로젝트 개요</h2>\n<p>Airflow를 활용해 다양한 데이터 워크플로우를 구성하고, 데이터를 처리하는 방식을 공부하고 실습합니다.</p>\n<h3>📊 사용된 기술 스택</h3>\n<ul>\n<li><strong>Docker</strong>: 애플리케이션을 컨테이너로 패키징하여 독립적으로 실행</li>\n<li><strong>Apache Airflow</strong>: 워크플로우 관리 플랫폼</li>\n<li><strong>Faker</strong>: 다양한 가짜 데이터를 생성하는 라이브러리</li>\n<li><strong>Kafka</strong>: 분산 스트리밍 플랫폼</li>\n<li><strong>PostgreSQL</strong>: 관계형 데이터베이스 관리 시스템</li>\n</ul>\n<h2>⚒️ 환경 설정</h2>\n<h2>💬 진행 상황</h2>\n<h3>1. Faker 라이브러리를 통해 가짜 데이터 생성</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from faker import Faker\nimport shortuuid\nfrom datetime import datetime\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\n\ndef create_fake_user() -> dict:\n    fake = Faker()\n    fake_profile = fake.profile()\n    \n    key_list = [\"name\", \"job\", \"residence\", \"blood_group\", \"sex\", \"birthdate\"]\n    fake_dict = {}\n\n    # 선택된 키의 값을 fake_dict에 추가\n    for key in key_list:\n        fake_dict[key] = fake_profile[key]\n        \n    fake_dict[\"phone_number\"] = fake.phone_number()\n    fake_dict[\"email\"] = fake.email()\n    fake_dict[\"uuid\"] = shortuuid.uuid()\n    # YYYYMMDD 변환\n    fake_dict['birthdate'] = fake_dict['birthdate'].strftime(\"%Y%m%d\")\n    fake_dict['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    return fake_dict\n\ndef generate_fake_data(num_records: int):\n    fake_users = []\n    for _ in range(num_records):\n        user = create_fake_user()\n        fake_users.append(user)\n    return fake_users\n\nif __name__ == \"__main__\":\n    data = generate_fake_data(30)\n    for user in data:\n        print(user)</code></pre></div>\n<h3>2. 모든 airflow 데이터 postgres에 저장.</h3>\n<ul>\n<li>Airflow 데이터 목록과 제가 만든 <strong>fake_data</strong> 목록 결과입니다.</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/airflow-ing/postgres_data_list.png\" alt=\"Airflow\"></p>\n<ul>\n<li><strong>fake_data</strong>의 데이터를 확인한 결과입니다.</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/jms0522/jms0522.github.io/main/content/images/airflow-ing/postgres_data_show.png\" alt=\"Airflow\"></p>\n<h2>3. 데이터 Kafka에 전달</h2>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> Postgres에 있는 데이터를 읽어서 Kafka로 보내기.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Airflow DAG를 이용해 스케줄러를 통해 관리하기.\n<ul>\n<li>Kafka에 데이터 전송하는 과정에서 계속 문제가 발생함.</li>\n</ul>\n</li>\n</ul>\n<h1>📌 진행하고 싶은 작업</h1>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Airflow를 통해 스트리밍 데이터 배치 처리하기.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> 데이터 정합성 보장</li>\n</ul>","categories":["Airflow","ALL"],"date":"August 27, 2024","description":"Airflow 간단한 실습입니다.","id":"01a6679a-fa0d-5d50-a3ab-a915f9b7eba2","keywords":["Workflow","Pipeline","Data","Blog","Airflow","Scheduler"],"slug":"/my-first-article/About-Airflow-Practice/","title":" 🌟 [Airflow] Airflow Practice ","readingTime":{"text":"3 min read"}},"listingPagePath":"/blog"}},"staticQueryHashes":["3262260831","948380417"],"slicesMap":{}}